# 第二章 线程同步精要

线程同步的四项原则，按重要性排列：
1.首要原则是尽量最低限度地共享对象，减少需要同步的场合。一个对象能不暴露给别的线程就不要暴露，如果要暴露，优先考虑immutable对象，实在不行才暴露可修改的对象，并用同步措施来充分保护它。

2.优先使用**高级同步工具**，其次是使用高级的并发编程构件，如TaskQueue、Producer-Consumer Queue、CountDownLatch（计数器闭锁，它是一种计数器，初始时设置一个计数值，并在多个线程完成各自任务后递减这个计数值，当计数值达到零时，允许某个等待的线程继续执行）等。

`TaskQueue`（任务队列）：自动在后台线程顺序执行任务。

`Producer-Consumer Queue`：生产者线程往队列放任务，消费者线程取任务执行。

`CountDownLatch`：比如等多个线程都完成初始化后再启动主线程。

3.必须用锁时，也要慎重挑选! 最后不得已必须使用底层同步原语（primitives）时，只用非递归的互斥器和条件变量，慎用读写锁（它们适用于读操作频繁而写操作较少的情况，使用不当可能会导致性能问题，需要仔细评估使用场景），不要用信号量。

> 1. 只用：
>    - 非递归互斥锁 `std::mutex`
>    - 条件变量 `std::condition_variable`
> 2. 慎用：
>    - 读写锁 `std::shared_mutex`（只适用于**读多写少**场景）
> 3. 避免使用：
>    - **信号量**（比如 `sem_t`）：底层复杂、难维护；
>    - **递归锁**（比如 `std::recursive_mutex`）：容易隐藏设计错误。

4.除了使用atomic整数外，不自己编写lock-free代码（编写无锁（lock-free）代码是一项极具挑战性的任务，需要深入了解硬件和多线程编程的细节），也不要用内核级同步原语（如memory barrier）。不凭空猜测哪种做法性能会更好，如spin lock vs. mutex。

`atomic<int>` 这种 **原子变量**是可以安全使用的；

但不要自己用 `std::atomic` 写复杂的无锁队列、无锁栈、CAS 循环等；

也不要碰什么 **memory barrier / 内存栅栏**、CPU 缓存一致性等底层问题。

次要原则有：
1.不使用跨进程的mutex，进程间通信只用TCP sockets。

2.加锁、解锁在同一个线程，线程a不能去unlock线程b已经锁住的mutex（RAII自动保证）。

3.别忘了解锁（RAII自动保证）。

4.不重复解锁（RAII自动保证）。

5.必要的时候考虑用PTHREAD_MUTEX_ERRORCHECK来排错。这种类型的互斥锁在锁定和解锁操作时会执行额外的错误检查，如果违反了互斥锁的使用规则，例如线程尝试解锁未锁定的互斥锁，或者尝试嵌套锁定同一个互斥锁，互斥锁会返回错误代码而不是阻塞或成功。它的性能更慢，通常用于调试和测试阶段。

### ===

如果确实需要在遍历时修改vector，有两种做法，一是把修改推后，记住循环中试图添加或删除哪些元素，等循环结束了再依记录修改foos；二是用copy-on-write，下面会介绍。

如果一个函数既可能在已加锁的情况下调用，又可能在未加锁的情况下调用，那就拆成两个函数：
 1.跟原来的函数同名，函数加锁，转而调用第2个函数。

2.给函数名加上后缀WithLockHold，不加锁，把原来的函数体搬过来。

```C++
void doSomething() {
    std::lock_guard<std::mutex> lock(mutex_);
    doSomethingWithLockHeld();  // 实际逻辑
}
void doSomethingWithLockHeld() {
    // 实际操作代码，但不加锁
    // 因为调用者已经持有锁
}
```

死锁会让程序行为失常，而其他锁使用不当会影响性能。编写高性能多线程程序还需了解false sharing和CPU cache效应：

1. false sharing：这是一种性能问题，它发生在多线程程序中的不同线程同时访问共享内存中不同变量或数据结构的不同部分，而这些变量或数据结构被映射到相同的缓存行（cache line）。因为现代CPU通常以缓存行为单位来加载和存储数据，当不同线程访问同一缓存行时，会导致缓存一致性开销，可能会使程序的性能大幅下降。False sharing会引发不必要的缓存失效，因为一个线程的写操作会导致其他线程的缓存无效，尽管它们实际上并没有修改相同的数据。

   解决False Sharing的方法通常包括使用线程本地存储（Thread-Local Storage）或者对共享数据进行对齐，以确保不同线程访问的数据不会映射到相同的缓存行。

缓存行（cache line）用于缓存数据以提高内存访问性能。缓存行是缓存的最小单位，通常由一组相邻的字节或字组成。当处理器从主内存中加载数据时，它会将一整个缓存行的数据复制到高速缓存中。这个缓存行中的数据可以是指令或数据，具体取决于缓存的类型（指令缓存或数据缓存）。

> ### 什么是伪共享？
>
> 假设你有两个线程：
>
> - 线程A在改变量 `a`
> - 线程B在改变量 `b`
>
> 它们改的是不同变量，本来互不干扰。但是如果 `a` 和 `b` 恰好落在了**同一个CPU缓存行（cache line）**上，就会产生“假共享”问题。
>
> ### 💥 为什么叫“假共享”？
>
> 因为：
>
> - 线程A写 `a`，会让B线程缓存的 `b` 失效（虽然它并没有改 `b`）
> - 然后B必须重新从主内存读取 `b`
> - 就这样你一写我一读，互相“抢缓存”，导致缓存频繁失效（**cache miss**），性能极差。
>
> ### ✅ 怎么解决？
>
> - **避免不同线程操作落在同一个缓存行的变量**
> - 方法有：
>   - 用 **线程本地变量**（Thread Local Storage）
>   - 给结构体加上 `padding` 或 `alignas(64)` 等对齐方式，让变量彼此远离（64字节大约就是一行cache）

2. CPU Cache效应：指利用CPU的缓存来提高程序性能的现象。CPU缓存是一种用于存储频繁访问的数据的高速存储器，以减少对主内存的访问延迟。当多线程程序访问相同的数据时，合理地利用缓存可以显著提高性能。但同时，不恰当的缓存使用也可能导致性能下降。

CPU Cache效应包括缓存命中（数据在缓存中）和缓存未命中（数据不在缓存中）。为了获得最佳性能，我们需要考虑数据的局部性，以减少缓存未命中，并避免False Sharing。

> ### 有效利用CPU缓存会带来性能提升
>
> - 当你频繁使用一块内存区域（比如遍历数组），CPU能将它加载到高速缓存中，下次访问就“秒出”——这叫 **cache hit**
> - 如果缓存中没数据，CPU就要去主内存取，这叫 **cache miss**，慢得多。
>
> ### ❗不当使用反而降低性能
>
> - 比如前面说的 False Sharing
> - 又如随意地访问不连续的内存（比如散乱访问大数组），容易导致 cache miss
>
> ### 💡小技巧：**访问数据要局部化（locality）**
>
> - 一次性处理一组连续的数据，比跳来跳去访问内存快很多
> - 这也是为什么 **结构体排布顺序**、数组遍历顺序，都很重要

3. 互斥器 mutex 是“排他访问”工具，不是“等待条件”的工具

- mutex 的用途：让多个线程不要同时操作同一块数据
- 用法：线程先 `lock`，访问数据，再 `unlock`
- ⚠️ 你不应该长时间持有锁，也不应该在拿不到锁时长期等待，最好立即拿到就用完

4. 真正“等待某个条件”时，用的是 **条件变量（condition variable）**

- mutex 是“防冲突”
- **condition variable** 是“等条件”

Full Memory Barrier

内存屏障是一种 **屏蔽 CPU 和编译器重排序行为** 的手段，它确保多线程间对内存的读写顺序和可见性。

Full memory barrier 的作用包括：

- 保证顺序性（**防止重排序**）：

让 CPU 保证你写的代码执行顺序与语义顺序一致，比如：

```cpp
a = 1;
__memory_barrier__();  // 假设存在
b = 2;
```

- 保证可见性：

写操作在 barrier 前完成，并刷新到主内存；而其他线程读取时从主内存拿到的是最新的值。

倒计时（CountDownLatch）是一种常用且易用的同步手段，它的用途有：

1.主线程发起多个子线程，等这些子线程各自都完成一定的任务后，主线程才继续执行。通常用于主线程等待多个子线程完成初始化。

2.主线程发起多个子线程，子线程都等待主线程，主线程完成一些任务后通知所有子线程开始执行。通常用于多个子线程等待主线程发出起跑命令。

CountDownLatch的接口很简单：

```c++
class CountDownLatch : boost::noncopyable
{
public:
    // 倒数几次
    explicit CountDownLatch(int count);
    // 等待计数值变为0
    void wait();
    // 计数减一
    void countDown();

private:
    mutable MutexLock mutex_;
    Condition condition_;
    int count_;
};
void CountDownLatch::wait()
{
    MutexLockGuard lock(mutex_);
    while (count_ > 0)
    {
        condition_.wait();
    }
}

void CountDownLatch::countDown()
{
    MutexLockGuard lock(mutex_);
    --count_;
    if (count_ == 0) 
    {
        condition_.notifyAll();
    }
}
```

读写锁（Readers-Writer lock，简写为rwlock）看上去是个很美的抽象，它明确区分了read和write两种行为。

1. **容易错误地在读锁中修改数据**

你以为自己只是在“读数据”，用了读锁，但后来为了加新功能，误操作成了“写数据”，却还在用读锁！

```cpp
void traverse() {
    rwlock.readLock();
    foo.push_back(x);  // ❌ 错误：在读锁中修改共享数据！
    rwlock.readUnlock();
}
```

2. **性能不一定更高**

**rwlock 获取读锁的代价** ≈ **mutex 获取锁的代价**

- 它也得更新内部计数器（记录当前有多少reader）。

如果**临界区小**，**锁竞争不激烈**（例如每次访问只读取一个 int），那 mutex 反而更快。

有些平台上 mutex 是直接用原子操作实现的，反而 rwlock 还慢。

3. **读锁升级写锁的问题**

如果你先持有读锁（read lock），然后想“升级”为写锁（write lock），常见的问题有两种：

（1）系统**允许升级**（某些实现）：

你在遍历容器时加了读锁，然后想在中途写入：

```cpprwlock.readLock();
for (...) {
    if (shouldModify) {
        rwlock.upgradeToWrite();  // 写锁来了，迭代器可能失效
        container.erase(...);     // ❌ 修改容器，迭代器崩溃！
    }
}
rwlock.readUnlock();
```

（2）系统**不允许升级**（比如 POSIX pthread_rwlock）：

```cpp
rwlock.readLock();
// ...
rwlock.writeLock();  // ❌ 死锁：你自己读着还想写
```

4. **reader lock 可重入，writer lock 不可重入 + 饥饿问题**

多数 `rwlock` 允许一个线程多次持有 **读锁**（可重入），但写锁**不可重入**。

为了防止写线程“饿死”，大多数 rwlock **在有写锁等待时，会阻止后续读锁的获取**。

**MutexLock、MutexLockGuard、Condition等class都不允许拷贝构造和赋值。**

```cpp
class MutexLock : boost::noncopyable
{
public:
    MutexLock() : holder_(0)
    {
        pthread_mutex_init(&mutex_, NULL);
    }
    
    ~MutexLock()
    {
        assert(holder_ == 0);
        pthread_mutex_destory(&mutex_);
    }
    
    bool isLockedByThisThread()
    {
        return holder_ == CurrentThread::tid();
    }
    
    void assertLocked()
    {
        assert(isLockedByThisThread();
    }
    
    // 仅供MutexLockGuard调用，严禁用户代码调用
    void lock()
    {
        // 这两行顺序不能反
        pthread_mutex_lock(&mutex_);
        holder_ = CurrentThread::tid();
    }
    
    // 仅供MutexLockGuard调用，严禁用户代码调用
    void unlock()
    {
        // 这两行顺序不能反
        holder_ = 0;
        pthread_mutex_unlock(&mutex_);
    }
    
    // 仅供Condition调用，严禁用户代码调用
    pthread_mutex_t *getPthreadMutex()
    {
        return &mutex_;
    }

private:
    pthread_mutex_t mutex_;
    pid_t holder_;
};

class MutexLockGuard : boost::noncopyable
{
public:
    explicit MutexLockGuard(MutexLock &mutex) : mutex_(mutex)
    {
        mutex_.lock();
    }
    
    ~MutexLockGuard()
    {
        mutex_.unlock();
    }

private:
    MutexLock &mutex_;
};

#define MutexLockGuard(x) static_assert(false, "missing mutex guard var name");
// 以上代码最后定义了一个宏，作用是防止程序里出现以下错误
void doit()
{
    // 遗漏变量名，产生一个临时对象又马上销毁了
    MutexLockGuard(mutex);
    // 没有锁住临界区
    // 正确写法是MutexLockGuard lock(mutex);
    // 临界区
}
```

以下muduo::Condition class简单地封装了Pthreads condition variable，用起来也容易，这里用notify/notifyAll作为函数名，因为signal有别的含义，C++里的signal/slot、C里的signal handler等，就不overload这个术语了。
```cpp
class Condition : boost::noncopyable
{
public:
    explicit Condition(MutexLock &mutex) : mutex_(mutex)
    {
        pthread_cond_init(&pcond_, NULL);
    }
    
    ~Condition()
    {
        pthread_cond_destory(&pcond_);
    }
    
    void wait()
    {
        pthread_cond_wait(&pcond_, mutex_.getPthreadMutex());
    }
    
    void notify()
    {
        pthread_cond_signal(&pcond_);
    }
    
    void notifyAll()
    {
        pthread_cond_broadcast(&pcond_);
    }

private:
    MutexLock &mutex_;
    pthread_cond_t pcond_;
};
```

"acquire"和"release"是一种内存操作语义，用于确保对共享数据的读取和写入操作在多线程环境下的正确同步：
1.Acquire (获取)：当一个线程执行"acquire"操作时，它确保之前的所有读取和写入操作都已经完成。这意味着在"acquire"操作之前的所有写入都将在该操作之前对其他线程可见。"Acquire"语义通常与读取操作相关联，以确保在读取之前所有必要的写入都已完成。

2.Release (释放)：当一个线程执行"release"操作时，它确保之后的所有读取和写入操作都不会提前执行。这意味着在"release"操作之后的所有写入都将在该操作之后对其他线程可见。"Release"语义通常与写入操作相关联，以确保在写入之后所有必要的读取都不会提前执行。

